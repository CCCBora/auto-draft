\begin{abstract}
In this paper, we present a novel Decentralized Atari Learning (DAL) algorithm for playing Atari games using decentralized reinforcement learning. Our proposed method combines the strengths of both value-based and policy-based decentralized RL techniques and introduces a unique communication mechanism that enables agents to share information and coordinate their actions while preserving privacy and reducing communication overhead. Through a comprehensive experimental evaluation, we demonstrate the effectiveness of our algorithm in addressing the challenges of high-dimensional sensory input and complex decision-making processes in Atari games. Our experimental results show that the DAL algorithm achieves competitive performance in terms of cumulative reward, outperforming the decentralized Dec-PG method and maintaining comparable performance with the centralized DQN and A3C methods. In terms of training time and communication overhead, the DAL algorithm exhibits significant improvements over the centralized methods, highlighting its scalability and privacy-preserving capabilities. Our work contributes to the growing body of research in decentralized reinforcement learning, offering valuable insights into the trade-offs between scalability, privacy, and performance in this domain.
\end{abstract}